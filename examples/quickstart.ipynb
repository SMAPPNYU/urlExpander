{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# urlExpander Quickstart\n",
    "[NBViewer](http://nbviewer.jupyter.org/https://github.com/SMAPPNYU/urlExpander/blob/master/examples/quickstart.ipynb) | [Github](https://github.com/SMAPPNYU/urlExpander/blob/master/examples/quickstart.ipynb)| By [Leon Yin](leonyin.org) for [SmaPP NYU](https://wp.nyu.edu/smapp/)\n",
    "\n",
    "\n",
    "The core functions for this package as exactly as the name suggests -- to expand shortened urls!<br>\n",
    "You can download the software using pip:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting urlexpander\n",
      "  Downloading https://files.pythonhosted.org/packages/b5/f9/4b378696a9a631390792041aabeb39ca779a7f96d01ace5f80e155e7611d/urlexpander-0.0.14.tar.gz\n",
      "Requirement already up-to-date: runtimestamp in /home/ly501/anaconda3/lib/python3.6/site-packages\n",
      "Requirement already up-to-date: tldextract in /home/ly501/anaconda3/lib/python3.6/site-packages (from urlexpander)\n",
      "Requirement already up-to-date: pandas in /home/ly501/anaconda3/lib/python3.6/site-packages (from urlexpander)\n",
      "Requirement already up-to-date: numpy in /home/ly501/anaconda3/lib/python3.6/site-packages (from urlexpander)\n",
      "Requirement already up-to-date: tqdm in /home/ly501/anaconda3/lib/python3.6/site-packages (from urlexpander)\n",
      "Requirement already up-to-date: unshortenit in /home/ly501/anaconda3/lib/python3.6/site-packages (from urlexpander)\n",
      "Requirement already up-to-date: requests-file>=1.4 in /home/ly501/anaconda3/lib/python3.6/site-packages (from tldextract->urlexpander)\n",
      "Requirement already up-to-date: requests>=2.1.0 in /home/ly501/anaconda3/lib/python3.6/site-packages (from tldextract->urlexpander)\n",
      "Requirement already up-to-date: idna in /home/ly501/anaconda3/lib/python3.6/site-packages (from tldextract->urlexpander)\n",
      "Requirement already up-to-date: setuptools in /home/ly501/anaconda3/lib/python3.6/site-packages (from tldextract->urlexpander)\n",
      "Requirement already up-to-date: pytz>=2011k in /home/ly501/anaconda3/lib/python3.6/site-packages (from pandas->urlexpander)\n",
      "Requirement already up-to-date: python-dateutil>=2.5.0 in /home/ly501/anaconda3/lib/python3.6/site-packages (from pandas->urlexpander)\n",
      "Requirement already up-to-date: click>=6.7 in /home/ly501/anaconda3/lib/python3.6/site-packages (from unshortenit->urlexpander)\n",
      "Requirement already up-to-date: lxml>=4.1.1 in /home/ly501/anaconda3/lib/python3.6/site-packages (from unshortenit->urlexpander)\n",
      "Requirement already up-to-date: six in /home/ly501/anaconda3/lib/python3.6/site-packages (from requests-file>=1.4->tldextract->urlexpander)\n",
      "Requirement already up-to-date: certifi>=2017.4.17 in /home/ly501/anaconda3/lib/python3.6/site-packages (from requests>=2.1.0->tldextract->urlexpander)\n",
      "Requirement already up-to-date: chardet<3.1.0,>=3.0.2 in /home/ly501/anaconda3/lib/python3.6/site-packages (from requests>=2.1.0->tldextract->urlexpander)\n",
      "Requirement already up-to-date: urllib3<1.24,>=1.21.1 in /home/ly501/anaconda3/lib/python3.6/site-packages (from requests>=2.1.0->tldextract->urlexpander)\n",
      "Building wheels for collected packages: urlexpander\n",
      "  Running setup.py bdist_wheel for urlexpander ... \u001b[?25ldone\n",
      "\u001b[?25h  Stored in directory: /home/ly501/.cache/pip/wheels/e8/e9/fc/eeaa5575adcb39244121bc017c8954365b224d23aa41aa4e2d\n",
      "Successfully built urlexpander\n",
      "Installing collected packages: urlexpander\n",
      "  Found existing installation: urlexpander 0.0.13\n",
      "    Uninstalling urlexpander-0.0.13:\n",
      "      Successfully uninstalled urlexpander-0.0.13\n",
      "Successfully installed urlexpander-0.0.14\n",
      "\u001b[33mYou are using pip version 9.0.3, however version 10.0.1 is available.\n",
      "You should consider upgrading via the 'pip install --upgrade pip' command.\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!pip install urlexpander runtimestamp --upgrade"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Updated 2018-07-12 17:30:37.392022\n",
      "By Leon\n",
      "Using Python 3.6.5\n",
      "On Linux-3.10.0-514.10.2.el7.x86_64-x86_64-with-centos-7.3.1611-Core\n"
     ]
    }
   ],
   "source": [
    "import urlexpander as ux\n",
    "from runtimestamp.runtimestamp import runtimestamp\n",
    "runtimestamp('Leon')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here is a toy example of some URLs taken from Congressional Twitter accounts:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "urls = [\n",
    "    'https://trib.al/xXI5ruM',\n",
    "    'http://bit.ly/1Sv81cj',\n",
    "    'https://www.youtube.com/watch?v=8NwKcfXvGl4',\n",
    "    'https://t.co/zNU1eHhQRn',\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can use the `expand` function (see the code) to unshorten any link:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'original_url': 'https://trib.al/xXI5ruM',\n",
       " 'resolved_domain': 'breitbart.com',\n",
       " 'resolved_url': 'https://www.breitbart.com/video/2017/12/31/lindsey-graham-trump-just-cant-tweet-iran/'}"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ux.expand(urls[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To save compute time, we can skip links that don't need to be expanded.<br>\n",
    "The `is_short` function takes any url and checks if the domain is from a known list of link shorteners"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "http://bit.ly/1Sv81cj returns:\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(f\"{urls[1]} returns:\")\n",
    "ux.is_short(urls[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "bit.ly is probably the best known link shortener, Youtube.com however is not a link shortener!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "https://www.youtube.com/watch?v=8NwKcfXvGl4 returns:\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(f\"{urls[2]} returns:\")\n",
    "ux.is_short(urls[2])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "urlExpander takes advantage of a list of known domains that offer link shortening services."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['sh.st',\n",
       " 'adf.ly',\n",
       " 'lnx.lu',\n",
       " 'adfoc.us',\n",
       " 'dlvr.it',\n",
       " 'bit.ly',\n",
       " 'buff.ly',\n",
       " 'ow.ly',\n",
       " 'goo.gl',\n",
       " 'shar.es',\n",
       " 'ift.tt',\n",
       " 'fb.me',\n",
       " 'washex.am',\n",
       " 'smq.tc',\n",
       " 'trib.al',\n",
       " 'is.gd',\n",
       " 'paper.li',\n",
       " 'waa.ai',\n",
       " 'tinyurl.com',\n",
       " 'ht.ly',\n",
       " '1.usa.gov',\n",
       " 'deck.ly',\n",
       " 'bit.do',\n",
       " 'tiny.cc',\n",
       " 'lc.chat']"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "known_shorteners = ux.constants.all_short_domains.copy()\n",
    "known_shorteners[:25]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can make modifications or use your own `list_of_domains` as an argument for the`is_short` function or `is_short_domain` (which is faster and operates on the domain-level)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "known_shorteners += ['youtube.com']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Now https://www.youtube.com/watch?v=8NwKcfXvGl4 returns:\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(f\"Now {urls[2]} returns:\")\n",
    "ux.is_short(urls[2], list_of_domains=known_shorteners)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we can shorten our workload:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['https://trib.al/xXI5ruM', 'http://bit.ly/1Sv81cj']"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# filter only domains that need to be shortenened\n",
    "urls_to_shorten = [link for link in urls if ux.is_short(link)]\n",
    "urls_to_shorten"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "urlExpander's `multithread_expand` does heavy lifting to quickly and thoroughly expand a list of links:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "1it [00:02,  2.13s/it]\n"
     ]
    }
   ],
   "source": [
    "resolved_links = ux.multithread_expand(urls_to_shorten,  \n",
    "                                       n_workers=2,\n",
    "                                       return_errors=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The output works really nicely with [Pandas](https://pandas.pydata.org/)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>original_url</th>\n",
       "      <th>resolved_domain</th>\n",
       "      <th>resolved_url</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>https://trib.al/xXI5ruM</td>\n",
       "      <td>breitbart.com</td>\n",
       "      <td>https://www.breitbart.com/video/2017/12/31/lin...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>http://bit.ly/1Sv81cj</td>\n",
       "      <td>billshusterforcongress.com</td>\n",
       "      <td>http://www.billshusterforcongress.com/congress...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              original_url             resolved_domain  \\\n",
       "0  https://trib.al/xXI5ruM               breitbart.com   \n",
       "1    http://bit.ly/1Sv81cj  billshusterforcongress.com   \n",
       "\n",
       "                                        resolved_url  \n",
       "0  https://www.breitbart.com/video/2017/12/31/lin...  \n",
       "1  http://www.billshusterforcongress.com/congress...  "
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "df_resolved_links = pd.DataFrame(resolved_links)\n",
    "df_resolved_links.tail(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "But that is a toy example, let's see how this fairs with a larger dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The dataset has 50000 rows\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>link.domain</th>\n",
       "      <th>link.url_long</th>\n",
       "      <th>link.url_short</th>\n",
       "      <th>tweet.created_at</th>\n",
       "      <th>tweet.id</th>\n",
       "      <th>tweet.text</th>\n",
       "      <th>user.id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>49998</th>\n",
       "      <td>youtube.com</td>\n",
       "      <td>https://www.youtube.com/watch?v=KzanCL2Ui4Y</td>\n",
       "      <td>https://t.co/Ilwci2gNFa</td>\n",
       "      <td>Mon Nov 28 19:44:30 +0000 2016</td>\n",
       "      <td>803323702444171265</td>\n",
       "      <td>LIVE: States' Economic Development Assistance ...</td>\n",
       "      <td>269992801</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49999</th>\n",
       "      <td>twitter.com</td>\n",
       "      <td>https://twitter.com/ap/status/818071378469519361</td>\n",
       "      <td>https://t.co/2SEKhfEXeB</td>\n",
       "      <td>Sun Jan 08 15:01:58 +0000 2017</td>\n",
       "      <td>818110504694595585</td>\n",
       "      <td>Prayers for #Jerusalem. https://t.co/2SEKhfEXeB</td>\n",
       "      <td>22055226</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       link.domain                                     link.url_long  \\\n",
       "49998  youtube.com       https://www.youtube.com/watch?v=KzanCL2Ui4Y   \n",
       "49999  twitter.com  https://twitter.com/ap/status/818071378469519361   \n",
       "\n",
       "                link.url_short                tweet.created_at  \\\n",
       "49998  https://t.co/Ilwci2gNFa  Mon Nov 28 19:44:30 +0000 2016   \n",
       "49999  https://t.co/2SEKhfEXeB  Sun Jan 08 15:01:58 +0000 2017   \n",
       "\n",
       "                 tweet.id                                         tweet.text  \\\n",
       "49998  803323702444171265  LIVE: States' Economic Development Assistance ...   \n",
       "49999  818110504694595585    Prayers for #Jerusalem. https://t.co/2SEKhfEXeB   \n",
       "\n",
       "         user.id  \n",
       "49998  269992801  \n",
       "49999   22055226  "
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_congress = ux.datasets.congress_twitter_links()\n",
    "print(f'The dataset has {len(df_congress)} rows')\n",
    "df_congress.tail(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "15035"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "short_urls = df_congress[df_congress['link.url_long'].apply(ux.is_short)]['link.url_long'].unique()\n",
    "len(short_urls)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's see how long it takes to expand these 15k links.<br>\n",
    "This is where the parameters for `multithread_expand` shine.\n",
    "We can created multiple threads for requests, cache results into a json, and chunk the 15k input into smaller pieces. Why does this last part matter? Something I noticed when expanding links in mass is that performance over time degrades. Chunking the input prevents this from happening (not sure why though)!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "12it [04:29, 22.47s/it]\n"
     ]
    }
   ],
   "source": [
    "resolved_links = ux.multithread_expand(short_urls, \n",
    "                                       chunksize=1280, \n",
    "                                       n_workers=64,\n",
    "                                       cache_file='tmp.json',\n",
    "                                       return_errors=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We were able to expand 15K links in less than 4.5 minutes!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The dataset has 50000 rows\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: []\n",
       "Index: []"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_resolved_links = pd.DataFrame(print(f'The dataset has {len(df_congress)} rows'))\n",
    "df_resolved_links.head(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This process has hsitorically been a huge bottleneck for using links as data. We hope that this software helps you overcome similar obsticles!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Congressman Shuster Endorses Donald Trump » Congressman Bill Shuster'"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ux.html_parser.get_webpage_title(urls[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'HOLLIDAYSBURG, PA –\\xa0Congressman Bill Shuster (R-PA), Chairman of the House Transportation and Infrastructure Committee and delegate for the 9th\\xa0Congressional District has announced his endorsement of Donald Trump for President: “The people of the 9th Congressional District, the Commonwealth of Pennsylvania, and states across the nation have made their voices heard, and I join them in ...Read more here.'"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ux.html_parser.get_webpage_description(urls[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
